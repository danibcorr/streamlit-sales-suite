# %% Libraries

import streamlit as st
from web_functions.language_state import StateManager

# %% Globals

if 'language' not in st.session_state:

    st.session_state.language = 'English'

# Create a single StateManager instance and store it in session state
if'state_manager' not in st.session_state:
    
    st.session_state.state_manager = StateManager(language=st.session_state.language)

state_manager = st.session_state.state_manager

# %% Parameters

st.set_page_config(
    page_title = "Home",
    page_icon = "ğŸ "
)

st.title("ğŸ  Home")

# %% Functions

def select_language(state_manager):

    language = state_manager.get_language()

    if (language == 'English') or (language == 'InglÃ©s'):
    
        language_options = ['English', 'Spanish']
        language = st.sidebar.selectbox('Select a language:', language_options)
    
    elif (language == 'Spanish') or (language == 'EspaÃ±ol'):
    
        language_options = ['InglÃ©s', 'EspaÃ±ol']
        language = st.sidebar.selectbox('Selecciona un idioma:', language_options)
    
    state_manager.set_language(language)
    st.session_state.language = language  
    
    return language

def text_home(state_manager):

    language = state_manager.get_language()
    
    if (language == 'English') or (language == 'InglÃ©s'):
    
        st.markdown("""
            # Abstract

            This project illustrates the application of **data analytics**, **data science** and **artificial intelligence** to extract meaningful information from sales data in second-hand markets. 
            sales data in second hand markets. It seeks to demonstrate competencies in these areas and to provide a practical solution for sales data management 
            for non-technical individuals. Several technologies are employed, which will be detailed in the subsequent sections.

            # Data analysis

            The first functionality is the â€œ**Data analysis**â€ page, where users can interact with graphs generated from a CSV file collected from sales data in second-tier markets. 
            data from sales data in second-hand markets. Currently, data collection is done manually and stored in Google Drive. The goal is to migrate 
            this database to a **SQL** database, which will allow real-time access and updates from this web application.

            The graphs provide information on **sales metrics**, such as monthly profit, best-selling products, and correlations between product characteristics, including gender, condition, and product 
            including gender, condition and country of sale.
        """)

        st.image('images/item_analysis.png')

        st.markdown("""
            # Item classifier

            The second functionality is the â€œ**Item classifier**â€, which allows users to upload an image of an item for classification by an **artificial intelligence** model.
            This process seeks to automate data labeling, minimizing human intervention.

            The model, trained with **TensorFlow** and **Keras**, can identify and classify various types of items. These items can be visualized on the **Data analysis** page.

            In particular, ConvNext was used with all layers of the model frozen during training due to computational limitations (laptop with 
            RTX 3060 with 6GB RAM, i7-11800H processor with 8 cores and 16 threads, and 16GB RAM). In order to reduce memory costs, training time and inference time, we used 
            inference time, mixed-precision systems using 16-bit floating-point precision were employed. The image data, ranging from 0 to 255, were stored as 8-bit unsigned integers, 
            reducing the processing time from 5 minutes to less than 1 minute for approximately 9,000 images. To improve the learning process learning process and model convergence, 
            gradient centralization and adaptive gradient clipping were used, along with the Adam optimization algorithm with weight decay.

            Model evaluation and artifact generation were performed using MLflow.
        """)

        st.image('images/item_classifier.png')

    elif (language == 'Spanish') or (language == 'EspaÃ±ol'):
    
        st.markdown("""
            # Resumen

            Este proyecto ilustra la aplicaciÃ³n de **anÃ¡lisis de datos**, **ciencia de datos** e **inteligencia artificial** para extraer informaciÃ³n significativa de los 
            datos de ventas en mercados de segunda mano. Se busca demostrar competencias en estas Ã¡reas y ofrecer una soluciÃ³n prÃ¡ctica para la gestiÃ³n de datos de ventas 
            para individuos no tÃ©cnicos. Se emplean diversas tecnologÃ­as, que se detallarÃ¡n en las secciones subsiguientes.

            # AnÃ¡lisis de datos

            La primera funcionalidad es la pÃ¡gina de "**AnÃ¡lisis de datos**", donde los usuarios pueden interactuar con grÃ¡ficos generados a partir de un archivo CSV recopilado 
            de datos de ventas en mercados de segunda mano. Actualmente, la recopilaciÃ³n de datos se realiza manualmente y se almacena en Google Drive. El objetivo es migrar 
            esta base de datos a una base de datos **SQL**, lo que permitirÃ¡ el acceso y las actualizaciones en tiempo real desde esta aplicaciÃ³n web.

            Los grÃ¡ficos ofrecen informaciÃ³n sobre **mÃ©tricas de ventas**, como el beneficio mensual, los productos mÃ¡s vendidos y las correlaciones entre las caracterÃ­sticas 
            del producto, incluyendo gÃ©nero, condiciÃ³n y paÃ­s de venta.
        """)

        st.image('images/item_analysis.png')

        st.markdown("""
            # Clasificador de artÃ­culos

            La segunda funcionalidad es el "**Clasificador de artÃ­culos**", que permite a los usuarios cargar una imagen de un artÃ­culo para su clasificaciÃ³n por un modelo 
            de **inteligencia artificial**. Este proceso busca automatizar el etiquetado de datos, minimizando la intervenciÃ³n humana.

            El modelo, entrenado con **TensorFlow** y **Keras**, puede identificar y clasificar varios tipos de artÃ­culos. Estos artÃ­culos pueden visualizarse en la pÃ¡gina de **AnÃ¡lisis de datos**.

            En particular, se utilizÃ³ ConvNext con todas las capas del modelo congeladas durante el entrenamiento debido a limitaciones computacionales (portÃ¡til con 
            RTX 3060 con 6GB de RAM, procesador i7-11800H con 8 nÃºcleos y 16 hilos, y 16GB de RAM). Para reducir los costos de memoria, el tiempo de entrenamiento y el 
            tiempo de inferencia, se emplearon sistemas de precisiÃ³n mixta utilizando precisiÃ³n de punto flotante de 16 bits. Los datos de imagen, que varÃ­an de 0 a 255, se almacenaron 
            como enteros sin signo de 8 bits, reduciendo el tiempo de procesamiento de 5 minutos a menos de 1 minuto para aproximadamente 9,000 imÃ¡genes. Para mejorar el proceso de 
            aprendizaje y la convergencia del modelo, se utilizaron la centralizaciÃ³n de gradientes y el recorte de gradientes adaptativo, junto con el algoritmo de optimizaciÃ³n Adam con decaimiento de pesos.

            La evaluaciÃ³n del modelo y la generaciÃ³n de artefactos se realizaron utilizando MLflow.
        """)

        st.image('images/item_classifier.png')

def main(state_manager: st.session_state.state_manager) -> None:

    select_language(state_manager)
    text_home(state_manager)

# %% Main

if __name__ == '__main__':

    main(state_manager)