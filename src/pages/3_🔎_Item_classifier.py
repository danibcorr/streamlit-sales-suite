import datetime

import streamlit as st
import pandas as pd
from deep_translator import GoogleTranslator

from models.inference_model import load_model, load_labels, make_prediction
from web_functions.language_state import StateManager
from config import config as cg

translator = GoogleTranslator(source="en", target="es")
language_manager = StateManager()
language = language_manager.language

page_title = "Item classifier"
page_title = translator.translate(page_title) if language != "English" else page_title
page_icon = "ðŸ”Ž"

st.set_page_config(page_title=page_title, page_icon=page_icon, layout="wide")
st.title(f"{page_icon} {page_title}")


@st.cache_resource
def load_model_inference(model_path: str, labels_path: str) -> tuple:
    """
    Load the model and labels from the given paths.

    Args:
        model_path (str): The path to the model file.
        labels_path (str): The path to the labels file.

    Returns:
        tuple: A tuple containing the loaded model and labels.
    """

    # Load labels from the given labels path
    dict_labels = load_labels(labels_path)

    # Load the model from the given model path with the number of classes equal to the number of labels
    model = load_model(model_path=model_path, num_classes=len(dict_labels))

    # Return the loaded model and labels as a tuple
    return model, dict_labels


def load_image(col) -> st.columns:
    """
    Create a file uploader for the given column.

    Args:
        col: The Streamlit column to create the uploader in.

    Returns:
        st.uploaded_file_manager: The file uploader object.
    """

    # Define the label for the file uploader
    label = "Upload an image from your computer."

    # Translate the label if the language is not English
    if language != "English":

        label = translator.translate(label)

    # Create a file uploader in the given column with the specified label and allowed file types
    return col.file_uploader(label, type=["png", "jpg", "jpeg"])


def data_filling(dataset_path: str, predictions_string: str) -> None:
    """
    Fill in missing data in the dataset based on the predictions and user input.

    Args:
        dataset_path (str): The path to the dataset CSV file.
        predictions_string (str): The predicted product type.

    Returns:
        None
    """

    # Read the CSV file into a pandas dataframe
    df = pd.read_csv(dataset_path)

    # Filter the data to obtain statistics based on the predicted product type
    df_product = df[df["Tipo producto"] == predictions_string]

    # Convert "Precio producto" to float once, replacing commas with dots
    df_product["Precio producto"] = (
        df_product["Precio producto"].str.replace(",", ".").astype("float32")
    )

    # Precompute modes and mean
    modes = (
        df_product[["Plataforma de venta", "Pais", "Genero", "Estado del producto"]]
        .mode()
        .iloc[0]
    )
    mean_price = df_product["Precio producto"].mean()

    # Get the column names
    column_names = df.columns.tolist()

    # Create a form with input fields for each column
    with st.form("my_form"):

        inputs = {}

        # Iterate over each column
        for column in column_names:

            # Handle different column types
            if column in modes.index:

                # Use mode value for categorical columns
                inputs[column] = st.text_input(column, value=modes[column])

            elif column == "Fecha de venta":

                # Use current date for date column
                now = datetime.datetime.now()
                inputs[column] = st.text_input(
                    column,
                    value=f"{str(now.day).zfill(2)}/{str(now.month).zfill(2)}/{now.year}",
                )

            elif column == "Precio producto":

                # Use mean price for price column
                inputs[column] = st.text_input(column, value=mean_price)

            elif column == "Tipo producto":

                # Use predicted product type for product type column
                inputs[column] = st.text_input(column, value=predictions_string)

            else:

                # Use empty input for other columns
                inputs[column] = st.text_input(column)

        # Add a submit button to the form
        submitted = st.form_submit_button("OK")

    # If the form is submitted, add the new row to the dataframe
    if submitted:

        # Create a new row from the input values
        new_row = {k: [v] for k, v in inputs.items()}
        new_row = pd.DataFrame(new_row)

        # Concatenate the new row with the original dataframe
        df = pd.concat([df, new_row], ignore_index=True)

        # Save the updated dataframe to the CSV file
        df.to_csv(dataset_path, index=False)

    # Display the updated dataframe
    st.dataframe(df, use_container_width=True)


def main(model_path: str, labels_path: str, dataset_path: str) -> None:
    """
    Main function to load the model, perform image classification, and fill in missing data.

    Args:
        model_path (str): The path to the model file.
        labels_path (str): The path to the labels file.
        dataset_path (str): The path to the dataset CSV file.
    """

    # Load the model and labels
    model, labels = load_model_inference(model_path, labels_path)

    # Create two columns in the Streamlit app
    col1, col2 = st.columns(2)

    # Create a file uploader in the first column
    file = load_image(col1)

    # If a file is uploaded, make a prediction and fill in missing data
    if file is not None:

        # Make a prediction using the uploaded image
        predictions_string = make_prediction(model, labels, file, col2)

        # Fill in missing data in the dataset based on the prediction
        data_filling(dataset_path, predictions_string)


if __name__ == "__main__":

    main(cg.MODEL_PATH, cg.LABELS_PATH, cg.DATASET_PATH)
